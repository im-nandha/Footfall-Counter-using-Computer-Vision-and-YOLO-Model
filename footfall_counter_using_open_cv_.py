# -*- coding: utf-8 -*-
"""Footfall Counter using Open CV .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l_Wp9GOCBjEUjOneWe5Gn421A2RtDEKu
"""

import cv2
import numpy as np
from scipy.spatial import distance as dist
import os

os.makedirs("footfall_project", exist_ok=True)

FPS = 20
FRAME_W, FRAME_H = 640, 360
DURATION = 12
N_FRAMES = FPS * DURATION

fourcc = cv2.VideoWriter_fourcc(*"mp4v")
synthetic_path = "footfall_project/synthetic_footfall.mp4"
writer = cv2.VideoWriter(synthetic_path, fourcc, FPS, (FRAME_W, FRAME_H))

people = [
    {"pos": np.array([100, -40], float), "vel": np.array([0, 2.0]), "size": (30, 50), "color": (0, 165, 255), "start": 10},
    {"pos": np.array([200, -40], float), "vel": np.array([0, 2.4]), "size": (28, 48), "color": (0, 255, 0), "start": 40},
    {"pos": np.array([300, FRAME_H+40], float), "vel": np.array([0, -2.1]), "size": (32, 52), "color": (255, 0, 0), "start": 80},
    {"pos": np.array([420, -40], float), "vel": np.array([0, 1.8]), "size": (30, 50), "color": (255, 165, 0), "start": 120},
    {"pos": np.array([520, FRAME_H+40], float), "vel": np.array([0, -2.6]), "size": (26, 46), "color": (128, 0, 128), "start": 160},
]

for f in range(N_FRAMES):
    frame = np.full((FRAME_H, FRAME_W, 3), 240, dtype=np.uint8)

    roi_y = FRAME_H // 2
    cv2.line(frame, (30, roi_y), (FRAME_W-30, roi_y), (50, 50, 200), 2)
    cv2.putText(frame, "ROI (count line)", (35, roi_y-10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (50, 50, 200), 1)

    for p in people:
        if f >= p["start"]:
            p["pos"] += p["vel"]
            x, y = int(p["pos"][0]), int(p["pos"][1])
            w, h = p["size"]

            top_left = (x - w//2, y - h//2)
            bottom_right = (x + w//2, y + h//2)

            if -100 < y < FRAME_H + 100:
                cv2.rectangle(frame, top_left, bottom_right, p["color"], -1)
                cv2.circle(frame, (x, y - h//2 - 6), 6, (220, 220, 220), -1)

    writer.write(frame)

writer.release()

print("✅ Synthetic video created!")

class CentroidTracker:
    def __init__(self, maxDisappeared=15, maxDistance=60):
        self.nextObjectID = 0
        self.objects = {}
        self.disappeared = {}
        self.tracks = {}
        self.maxDisappeared = maxDisappeared
        self.maxDistance = maxDistance

    def register(self, centroid):
        self.objects[self.nextObjectID] = centroid
        self.disappeared[self.nextObjectID] = 0
        self.tracks[self.nextObjectID] = [centroid]
        self.nextObjectID += 1

    def deregister(self, objectID):
        del self.objects[objectID]
        del self.disappeared[objectID]

    def update(self, rects):
        if len(rects) == 0:
            for oid in list(self.disappeared.keys()):
                self.disappeared[oid] += 1
                if self.disappeared[oid] > self.maxDisappeared:
                    self.deregister(oid)
            return self.objects

        inputCentroids = np.zeros((len(rects), 2), dtype="int")
        for (i, (x1, y1, x2, y2)) in enumerate(rects):
            cX = int((x1 + x2) / 2.0)
            cY = int((y1 + y2) / 2.0)
            inputCentroids[i] = (cX, cY)

        if len(self.objects) == 0:
            for i in range(len(inputCentroids)):
                self.register(tuple(inputCentroids[i]))

        else:
            objectIDs = list(self.objects.keys())
            objectCentroids = list(self.objects.values())
            D = dist.cdist(np.array(objectCentroids), inputCentroids)

            rows = D.min(axis=1).argsort()
            cols = D.argmin(axis=1)[rows]

            usedRows, usedCols = set(), set()

            for (row, col) in zip(rows, cols):
                if row in usedRows or col in usedCols:
                    continue

                if D[row, col] > self.maxDistance:
                    continue

                objectID = objectIDs[row]
                self.objects[objectID] = tuple(inputCentroids[col])
                self.tracks[objectID].append(tuple(inputCentroids[col]))
                self.disappeared[objectID] = 0

                usedRows.add(row)
                usedCols.add(col)

            unusedRows = set(range(0, D.shape[0])).difference(usedRows)
            unusedCols = set(range(0, D.shape[1])).difference(usedCols)

            for row in unusedRows:
                objectID = objectIDs[row]
                self.disappeared[objectID] += 1
                if self.disappeared[objectID] > self.maxDisappeared:
                    self.deregister(objectID)

            for col in unusedCols:
                self.register(tuple(inputCentroids[col]))

        return self.objects

cap = cv2.VideoCapture(synthetic_path)
processed_out = cv2.VideoWriter(
    "footfall_project/processed_footfall.mp4", fourcc, FPS, (FRAME_W, FRAME_H))

bg_subtractor = cv2.createBackgroundSubtractorMOG2(
    history=200, varThreshold=25, detectShadows=False)

ct = CentroidTracker(maxDisappeared=25, maxDistance=80)

total_in, total_out = 0, 0
roi_y = FRAME_H // 2

while True:
    ret, frame = cap.read()
    if not ret:
        break

    fgmask = bg_subtractor.apply(frame)

    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel, iterations=2)
    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_DILATE, kernel, iterations=2)

    contours, _ = cv2.findContours(
        fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    rects = []
    for c in contours:
        if cv2.contourArea(c) < 400:
            continue
        x, y, w, h = cv2.boundingRect(c)
        rects.append((x, y, x+w, y+h))

    objects = ct.update(rects)

    vis = frame.copy()
    cv2.line(vis, (30, roi_y), (FRAME_W-30, roi_y), (50, 50, 200), 2)

    for (objectID, centroid) in objects.items():
        cX, cY = centroid
        cv2.circle(vis, (cX, cY), 4, (0, 0, 255), -1)
        cv2.putText(vis, f"ID {objectID}", (cX-10, cY-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)

        pts = ct.tracks[objectID][-20:]
        for i in range(1, len(pts)):
            cv2.line(vis, pts[i-1], pts[i], (0, 255, 0), 2)

        if len(ct.tracks[objectID]) >= 2:
            y_prev = ct.tracks[objectID][-2][1]
            y_curr = ct.tracks[objectID][-1][1]

            if y_prev < roi_y and y_curr >= roi_y:
                total_in += 1
            elif y_prev > roi_y and y_curr <= roi_y:
                total_out += 1

    cv2.rectangle(vis, (10, 10), (200, 70), (255, 255, 255), -1)
    cv2.putText(vis, f"IN: {total_in}", (20, 35),
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 120, 0), 2)
    cv2.putText(vis, f"OUT: {total_out}", (20, 60),
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 120), 2)

    processed_out.write(vis)

cap.release()
processed_out.release()

print("✅ Processing complete! Video saved in footfall_project/")